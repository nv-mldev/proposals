\chapter{Introduction}
\label{chap:introduction}

To date, our problem statements have largely centered around static camera-based detections and analytics. However, a significant number of emerging industrial automation and physical collaboration scenarios involve cameras in motion. These mobile cameras—mounted on Powered Industrial Vehicles (PIVs), Automated Guided Vehicles (AGVs), Robotic Arms, and Autonomous Mobile Robots (AMRs)—present a paradigm shift in complexity and capability.

In these dynamic cases, the solution must evolve beyond simple detection and classification to address three core challenges:
\begin{enumerate}
    \item \textbf{Seeking and tracking} specific objects for a defined operational purpose.
    \item \textbf{Converting pixel-based detections} into actionable, real-world physical coordinates.
    \item \textbf{Enabling closed-loop actions}, allowing the robotic platform to interact with the object appropriately (e.g., pick, place, navigate, avoid).
\end{enumerate}

This proposal outlines the software framework to be developed by \textbf{DAI (Dhvani Analytic Intelligence)}. Our scope is to engineer the core intelligence modules. The physical platforms for testing and validation will be provided by our partners at Accenture. Our methodology prioritizes a simulation-first approach to de-risk development, followed by a phased deployment onto physical hardware, ordered by increasing system complexity.